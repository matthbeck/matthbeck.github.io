\documentclass[11pt]{amsart}
\usepackage{amssymb,amsmath,latexsym,enumerate,mathptmx,microtype}
\hoffset=0in 
\voffset=0in
\oddsidemargin=0in
\evensidemargin=0in
\topmargin=-.7in 
\textwidth=6.5in
\textheight=9.5in
\begin{document}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.4cm}
\thispagestyle{empty} 
\def\0{\mathbf 0}
\def\u{\mathbf u}
\def\v{\mathbf v}
\def\C{\mathbf{C}}
\def\F{\mathbf{F}}
\def\R{\mathbf{R}}
\def\Z{\mathbf{Z}}
\def\P{\mathcal{P}}
\newcommand\spn{\operatorname{span}}
\renewcommand\null{\operatorname{null}}
\newcommand\range{\operatorname{range}}
\newcommand\rank{\operatorname{rank}}

\begin{center} {\bf MATH 725 \qquad \qquad Homework Set 4 \qquad \qquad due 9/19/11} \end{center} 

\begin{enumerate}[(1)]

\item Suppose $V$ and $W$ are finite-dimensional vector spaces, $T \in L(V,W)$, and define $\rank(T) := \dim \range (T)$. Prove that if $\rank(T) = \dim W$ then $T$ is surjective.

\begin{proof}
Suppose $\rank(T) = \dim W$.
We know that $\range(T)$ is a subspace of $W$, so consider a basis of $\range(T)$, which we can then extend to a basis of $W$. But since $\rank(T) = \dim W$ these bases must have the same length, and so the basis of $\rank(T)$ is already a basis of $W$, whence $\range(T) = W$.
\end{proof}

\item Suppose $U$, $V$, and $W$ are finite-dimensional vector spaces, $S \in L(U,V)$, and $T \in L(V,W)$.
  \begin{enumerate}
  \item Show that $\rank(TS) \le \min(\rank(S), \rank(T ))$. 
  Give examples to show that both equality and strict inequality are possible. 
  Can two nonzero maps have composition equal to zero?
  \item If $S$ has a right inverse, show that $\rank(T S) = \rank(T )$.
  \item If $T$ has a left inverse, show that $\rank(TS) = \rank(S)$.
  \item Prove that the rank of a matrix (i.e., the rank of the underlying linear map) is not more than the number of rows or the number of columns of the matrix.
  \item A matrix is said to have \emph{maximal rank} if the rank is equal to the the minimum of the number of rows and the number of columns. Show that a matrix has maximal rank if and only it is either injective or surjective.
  \end{enumerate}

\begin{proof}
\begin{enumerate}

\item It suffices to show that $\rank(TS) \le \rank(S)$ and $\rank(TS) \le \rank(T)$. The latter follows directly from $\range(TS) \subseteq \range(T)$ (which we know by adapting the previous homework \#4).
To prove the former, note that
\[
  \dim U = \dim \null(TS) + \rank(TS)
  \qquad \text{ and } \qquad
  \dim U = \dim \null(S) + \rank(S) \, .
\]
Again by adaptation of the previous homework \#4, we know that $\null(TS) \subseteq \null(S)$ and thus $\rank(S) \ge \rank(TS)$.
An example that shows that $\rank(TS) = \min(\rank(S), \rank(T ))$ is possible is given by $S=T=$ identity map on an arbitrary vector space $U=V=W$.
An example that shows that $\rank(TS) < \min(\rank(S), \rank(T ))$ is possible is given by $U=V=W= \P_2(\R)$ and $S=T= \frac{ d }{ dx }$.

\item Suppose $SR$ is the identity map. By using part (a) twice,
\[
  \rank(T) \ge \rank(TS) \ge \rank(TSR) = \rank(T) \, ,
\]
and so we must have equality all around.
(One can also argue via surjectivity of $S$.)

\item Suppose $LT$ is the identity map. By using part (a) twice,
\[
  \rank(S) \ge \rank(TS) \ge \rank(LTS) = \rank(S) \, .
\]
(One can also argue via injectivity of $T$.)

\item The rank of a linear map $M$ is the dimension of $\range(M)$, which can be at most the dimension of the codomain of $M$, and that is the number of rows of the matrix corresponding to $M$.
By our dimension--null space--rank theorem, the rank of $M$ is also at most the dimension of the domain of $M$, which equals the number of columns of the matrix corresponding to $M$.

\item Suppose the linear map underlying $M$ is from $V$ to $W$. Then
\begin{align*}
  \rank(M) = \# \text{ rows of } M
  &\Longleftrightarrow \dim \range(M) = \dim W \\
  &\Longleftrightarrow \range(M) = W \, ,
\end{align*}
i.e., $M$ is surjective, and
\begin{align*}
  \rank(M) = \# \text{ columns of } M
  &\Longleftrightarrow \dim \range(M) = \dim V \\
  &\Longleftrightarrow \dim \null(M) \, ,
\end{align*}
i.e., $M$ is injective. \qedhere
\end{enumerate}
\end{proof}

\item Consider the linear operator $\frac{d}{dx} \in L(\P_n(\F))$ given by differentiation. Compute the matrix of $\frac{d}{dx}$ using the basis
  \begin{enumerate}
  \item $1, x, x^2, \dots, x^n$;
  \item $\binom x 0, \binom x 1, \dots, \binom x n$.
  \end{enumerate}

\begin{proof}[Solution]
\begin{enumerate}

\item Since $\frac{d}{dx} x^k = k \, x^{ k-1 }$, the matrix of $\frac{d}{dx}$ with respect to the monomial basis has entries $a_{ k-1, k } = k$ for $2 \le k \le n$ and $a_{ jk } = 0$ otherwise.

\item We claim that
\[
  \frac{ d }{ dx } \binom x k = \sum_{ j \ge 1 } \frac{ (-1)^{ j-1 } }{ j } \binom{ x }{ k-j } 
\]
(which is really a finite sum, as $\binom x j = 0$ when $j<0$ by definition)
and prove this by induction on $k$.
The base case $k=0$ just says $0=0$.
The induction step follows with
\begin{align*}
  \frac{ d }{ dx } \binom x k
  &= \frac{ d }{ dx } \left( \binom{ x }{ k-1 } + \binom{ x-1 }{ k-1 } \right) \\
  &= \sum_{ j \ge 1 } \frac{ (-1)^{ j-1 } }{ j } \binom{ x }{ k-1-j } + \sum_{ j \ge 1 } \frac{ (-1)^{ j-1 } }{ j } \binom{ x-1 }{ k-1-j } \\
  &= \sum_{ j \ge 1 } \frac{ (-1)^{ j-1 } }{ j } \left( \binom{ x }{ k-1-j } + \binom{ x-1 }{ k-1-j } \right) \\
  &= \sum_{ j \ge 1 } \frac{ (-1)^{ j-1 } }{ j } \binom{ x }{ k-j } \, .
\end{align*}
Thus the matrix of $\frac{ d }{ dx }$ with respect to the binomial-coefficient basis has entries
\[
  a_{ jk } = \begin{cases}
    \frac{ (-1)^{ k-j-1 } }{ k-j } & \text{ if } j<k, \\
    0 & \text{ otherwise.}
  \end{cases} \qedhere
\]
\end{enumerate}
\end{proof}

\item Suppose $V$ is a finite-dimensional vector space and $S, T \in L(V )$.
Prove that $ST$ is invertible if and only if both $S$ and $T$ are invertible.
Give an example that shows that this statement is not true for infinite-dimensional vector spaces.

\begin{proof}
Suppose $ST$ is invertible and so, in particular, $\null(ST) = \{ \0 \}$ and $\range(ST) = V$.
We have shown in a previous homework that $\null(T) \subseteq \null(ST) = \{ \0 \}$, and so $T$ is injective and (by a theorem from class) invertible.
We have also shown that $\range(S) \supseteq \range(ST) = V$, and so $S$ is surjective and (by the same theorem) invertible.

An example of how this statement can fail if $V$ is infinite dimensional is given by $V = \P(\R)$, $S(p(x)) = p'(x)$, and $T(p(x)) = \int_0^x p(t) \, dt$: by the Fundamental Theorem of Calculus, $ST$ is the identity map; however, $S$ is not injective.
\end{proof}

\item Suppose $V$ and $W$ are finite-dimensional vector spaces, and $U$ is a subspace of $V$.
Let $R: L(V,W) \to L(U,W)$ be the \emph{restriction map} defined by $(R(T))(u) = T(u)$.
  \begin{enumerate}
  \item Show that $R$ is linear.
  \item Show that $R$ is surjective.
  \item If $U$ is a proper subspace of $V$, show that the restriction map is not injective.
  \end{enumerate}

\begin{proof}
\begin{enumerate}

\item Given $S, T \in L(V,W)$ and $a \in \F$, we have for any $u \in U$
\[
  R(a \, S+T)(u) = a \, S(u) + T(u) = a \, R(S)(u) + R(T)(u) \, .
\]

\item Let $\left( \u_1, \u_2, \dots, \u_m \right)$ be a basis of $U$, and extend it to a basis $\left( \u_1, \u_2, \dots, \u_m, \v_1, \v_2, \dots, \v_n \right)$ of $V$.
Given $T \in L(U,W)$, define $S \in L(V,W)$ through
\[
  \v = \sum_{ j=1 }^m a_j \u_j + \sum_{ j=1 }^n b_j \v_j \qquad \mapsto \qquad S(\v) = \sum_{ j=1 }^m a_j T(\u_j) \, .
\]
This map $S$ is by definition linear, and $R(S) = T$.
Hence $R$ is surjective.

\item Let $m := \dim U$, $n := \dim V$, and $k := \dim W$.
Then we know from a theorem in class that $\dim L(V,W) = nk$ and $\dim L(U,W) = mk$.
If $U \subsetneq V$ then $m < n$, and so $\rank(R)$ (which is at most $\dim L(U,W)$) cannot be equal $\dim L(V,W)$, i.e., $R$ cannot be surjective. \qedhere

\end{enumerate}
\end{proof}

\end{enumerate}

\end{document}