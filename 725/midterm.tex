% This is a LaTeX2e file.

\documentclass[12pt]{amsart}
\usepackage{amssymb,amsmath,latexsym,enumerate,mathptmx,microtype}

\hoffset=0in 
\voffset=0in
\oddsidemargin=0in
\evensidemargin=0in
\topmargin=-.4in 
%\headsep=0in 
%\headheight=0in
\textwidth=6.5in
\textheight=9.5in

\def\phi{\varphi}
\def\Id{\mathrm I}
\def\0{\mathbf 0}
\def\b{\mathbf b}
\def\c{\mathbf c}
\def\e{\mathbf e}
\def\u{\mathbf u}
\def\v{\mathbf v}
\def\w{\mathbf w}
\def\x{\mathbf x}
\def\y{\mathbf y}
\def\C{\mathbf{C}}
\def\F{\mathbf{F}}
\def\R{\mathbf{R}}
\def\Z{\mathbf{Z}}
\def\P{\mathcal{P}}
\def\ds{\displaystyle}
\newcommand\spn{\operatorname{span}}
\renewcommand\null{\operatorname{null}}
\newcommand\range{\operatorname{range}}
\newcommand\rank{\operatorname{rank}}
\newcommand\tr{\operatorname{tr}}
\newcommand\norm[1]{\left|\left| #1 \right|\right|}
\newcommand\inner[2]{\left< #1, #2 \right>}

\begin{document}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.4cm}

\pagestyle{empty} 

%\Large

\begin{center} {\bf MATH 725 \qquad Midterm Exam \qquad 10/19/11 \qquad } \end{center} 

{\bf Part I} (in-class exam 1:10--2:00 p.m.)

\thispagestyle{empty} 

\begin{enumerate} 

\item Suppose $V$ and $W$ are vector spaces.
  \begin{enumerate} 
  \item Define what it means for a set $S \subseteq V$ to be a \emph{basis} of $V$.
  \item Define the \emph{dimension} of $V$.
  \item Suppose $V$ and $W$ are finite dimensional. Show that if $\dim V > \dim W$ then there exists a surjective linear map $V \to W$.
  \end{enumerate}

\begin{proof}[Proof of {\rm (c)}]
Fix bases $\left( \v_1, \v_2, \dots, \v_n \right)$ of $V$ and $\left( \w_1, \w_2, \dots, \w_m \right)$ for $W$; by assumption, we have $n > m$.
We know that a linear map $T: V \to W$ is determined by the images of $\v_1, \v_2, \dots, \v_n$, so we define $T$ through
\[
  T(\v_j) := \begin{cases}
    \w_j & \text{ if } j \ge m, \\
    \0 & \text{ otherwise. }
  \end{cases}
\]
Given $\sum_{ j=1 }^m a_j \, \w_j \in W$,
\[
  T \left( \sum_{ j=1 }^m a_j \, \v_j \right)
  = \sum_{ j=1 }^m a_j \, T(\v_j) \\
  = \sum_{ j=1 }^m a_j \, \w_j \, ,
\]
i.e., $T$ is surjective.
\end{proof}

\item Suppose $V$ and $W$ are vector spaces.
  \begin{enumerate} 
  \item Define what it means for a map $T: V \to W$ to be \emph{linear}.
  \item Define the \emph{null space} and the \emph{range} of $T$.
  \item Give an example of a linear map (e.g., by giving a matrix) that has a two-dimensional null space and a three-dimensional range.
  \end{enumerate}

\begin{proof}[Solution for {\rm (c)}]
Let $T \in L \left( \R^5 \right)$ given by the matrix
\[
  \left[ \begin{array}{ccccc}
    0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1
  \end{array} \right] . \qedhere
\]
\end{proof}

\item Suppose $V$ is a vector space and $T \in L(V)$.
  \begin{enumerate} 
  \item Define the notion of \emph{eigenvalue} and \emph{eigenvector} of $T$.
  \item Give an example of a linear map on a real vector space that has no eigenvalues.
  \item State a condition on $V$ or $T$ that guarantees that $T$ has an eigenvalue.
  \end{enumerate}

\begin{proof}[Solution]
\begin{enumerate}[(a)]

\item[(b)]
Let $T \in L \left( \R^2 \right)$ given by the matrix
\[
  \left[ \begin{array}{cc}
    0 & -1 \\
    1 & 0
  \end{array} \right] .
\]

\item[(c)]
$V$ is a complex vector space.
(Alternative I: $V$ has a basis with respect to which $T$ is upper triangular.)
(Alternative II: $T$ is self adjoint.) \qedhere

\end{enumerate}
\end{proof}

\newpage

\item Suppose $V$ is a complex inner-product space and $T \in L(V)$.
  \begin{enumerate} 
  \item Define $T^*$.
  \item Define what it means for $T$ to be \emph{self adjoint} and what it means to be \emph{normal}.
  \item Show that any self-adjoint operator is normal.
  \end{enumerate}

\end{enumerate}

\begin{proof}[Proof of {\rm (c)}]
Suppose $T = T^*$. Then $T T^* = T^2 = T^* T$, i.e., $T$ is normal.
\end{proof}

\vspace{20pt}

{\bf Part II} (take-home exam, due on 10/21/11 at 1:00 p.m.)

{\it
You are welcome to use book and internet sources, but you are not allowed to discuss this exam with anyone (including your class mates).

Show complete work---that is, all the steps needed to completely justify your answer. Simplify your answers as much as possible. 
You may refer to theorems in the text book and homework problems.
}

\begin{enumerate} 

\item Suppose $\left( \v_1, \v_2, \dots, \v_n \right)$ is a linearly independent list of vectors in some vector space.
  \begin{enumerate} 
  \item Is the list $\left( \v_2 - \v_1, \v_3 - \v_2, \dots, \v_n - \v_{ n-1 } \right)$ linearly independent?
  \item Is the list $\left( \v_2 - \v_1, \v_3 - \v_2, \dots, \v_n - \v_{ n-1 }, \v_1 - \v_n \right)$ linearly independent?
  \end{enumerate}

\begin{proof}
\begin{enumerate}

\item Yes: if $a_1, a_2, \dots, a_{ n-1 } \in \F$ satisfy
\begin{align*}
  0
  &= a_1 \left( \v_2 - \v_1 \right) + a_2 \left( \v_3 - \v_2 \right) + \dots + a_{n-1} \left( \v_n - \v_{n-1} \right) \\
  &= - a_1 \v_1 + \left( a_1 - a_2 \right) \v_2 + \left( a_2 - a_3 \right) \v_3 + \dots + \left( a_{ n-1 } - a_n \right) \v_n \, ,
\end{align*}
then (since $\v_1, \v_2, \dots, \v_n$ are linearly independent) $a_1 = 0$, $a_1 - a_2 = 0$ (and thus $a_2 = 0$), $a_2 - a_3 = 0$ (and thus $a_3 = 0$), etc., down to $a_n = 0$.

\item No, because the sum of these vectors is zero. \qedhere

\end{enumerate}
\end{proof}

\item Let $M$ be the vector space of all real $n \times n$ matrices, for some fixed $n \in \Z_{ >0 }$.
For $A = \left( a_{ jk }  \right) \in M$, define the \emph{trace} of $A$ as
\[
  \tr(A) := \sum_{ j=1 }^n a_{ jj } \, .
\]
  \begin{enumerate} 
  \item Show that $U := \left\{ A \in M : \, \tr(A) = 0 \right\}$ is a subspace of $M$.
  \item Compute the dimension of $U$. % \footnote{\emph{Hint:} first show that the trace map is linear.}
  \end{enumerate}

\begin{proof}
\begin{enumerate}

\item The zero matrix has trace zero, and for $A = \left( a_{ jk } \right)$, $B = \left( b_{ jk } \right)$, and $r \in \R$, then
\[ \qquad \qquad
  \tr(r \, A + B)
  = \sum_{ j=1 }^n \left( r \, a_{ jj } + b_{ jj } \right)
  = r \sum_{ j=1 }^n a_{ jj } + \sum_{ j=1 }^n b_{ jj }
  = r \, \tr(A) + \tr(B) \, , \qquad (\star)
\]
and so if $\tr(A) = \tr(B) = 0$, we have $\tr(r \, A + B) = 0$.

\item Considering the trace as a map $\tr : M \to \R$, we showed in $(\star)$ that $\tr$ is linear.
But $U$ is, by definition, the null space of $\tr$. Since $\tr$ is surjective (we can reach any $r \in \R$ by considering a matrix with $a_{ 11 } = r$ and all other entries 0), we have
\[
  n^2
  = \dim M
  = \dim \null(\tr) + \range(\tr)
  = \dim U + 1 \, ,
\]
and thus $\dim U = n^2 - 1$. \qedhere

\end{enumerate}
\end{proof}

\item Find a polynomial $p \in \P_2(\R)$ such that
\[
  \int_{ -1 }^1 \sin(x) \, q(x) \, dx = \int_{ -1 }^1 p(x) \, q(x) \, dx
\]
for all $q \in \P_2(\R)$.

\begin{proof}
Consider the inner product $\inner p q := \int_{ -1 }^1 p(x) \, q(x) \, dx$ on $\P_2(\R)$.
In HW 7, we computed the orthonormal basis
\[
  \left( \tfrac{ 1 }{ \sqrt 2 } , \sqrt{ \tfrac 3 2 } \, x , \sqrt{ \tfrac{ 45 }{ 8 }  }  \left( x^2 - \tfrac{ 1 }{ 3 } \right) \right) .
\]
By the linearity properties of an integral, we can view
\[
  \phi(q) := \int_{ -1 }^1 \sin(x) \, q(x) \, dx
\]
as a linear functional on $\P_2(\R)$, and so we can apply (the proof of) Theorem 6.45 in the book (or from the lecture notes):
\[
  \phi(q)
  = \inner q { \phi \left( \tfrac{ 1 }{ \sqrt 2 } \right) \tfrac{ 1 }{ \sqrt 2 } + \phi \left( \sqrt{ \tfrac 3 2 } \, x \right) \sqrt{ \tfrac 3 2 } \, x + \phi \left( \sqrt{ \tfrac{ 45 }{ 8 } } \left( x^2 - \tfrac{ 1 }{ 3 } \right) \right) \sqrt{ \tfrac{ 45 }{ 8 } } \left( x^2 - \tfrac{ 1 }{ 3 } \right) } .
\]
We compute
\begin{align*}
  \phi \left( \tfrac{ 1 }{ \sqrt 2 } \right)
  &= \tfrac{ 1 }{ \sqrt 2 } \int_{ -1 }^1 \sin(x) \, dx
  = 0 \\
  \phi \left( \sqrt{ \tfrac 3 2 } \, x \right)
  &= \sqrt{ \tfrac 3 2 } \int_{ -1 }^1 x \, \sin(x) \, dx
  = \sqrt 6 \left( \sin(1) - \cos(1) \right) \\
  \phi \left( \sqrt{ \tfrac{ 45 }{ 8 } } \left( x^2 - \tfrac{ 1 }{ 3 } \right) \right)
  &= \sqrt{ \tfrac{ 45 }{ 8 } } \int_{ -1 }^1 \left( x^2 - \tfrac{ 1 }{ 3 } \right) \sin(x) \, dx
  = 0 \, ,
\end{align*}
and so
\[
  \phi(q)
  = \inner q { \sqrt 6 \left( \sin(1) - \cos(1) \right) \sqrt{ \tfrac 3 2 } \, x }
  = 3 \left( \sin(1) - \cos(1) \right) \int_{ -1 }^1 x \, q(x) \, dx \, .
\]
Thus $p(x) = 3 \left( \sin(1) - \cos(1) \right) x$.
\end{proof}

\item A linear operator $T \in L(V)$ is \emph{nilpotent} if there exists $k \in \Z_{ >0 }$ such that $T^k = 0$.\footnote{Here 0 is the linear operator that returns $\0$ for every input vector.}
  \begin{enumerate} 
  \item Prove that if $T$ is nilpotent, then $0$ is the only eigenvalue of $T$.
  \item Show that if $T$ is nilpotent and self adjoint, then $T=0$. 
  \end{enumerate}

\begin{proof}
\begin{enumerate}

\item Suppose $T^k = 0$ and $k$ is the smallest positive integer with this property.
If $k = 1$, $T$ is the zero map, which certainly has 0 as an eigenvalue.
If $k > 1$, then there exists $\v \in V$ such that $T^{ k-1 } (\v) \ne \0$, and so (because $T \left( T^{ k-1 } (\v) \right) = \0 = 0 \, \v$) 0 is an eigenvalue of $T$.

Now suppose $\lambda$ is another eigenvalue with eigenvector $\v \ne \0$.
Then $\0 = T^k (\v) = \lambda^k \, \v$ and so $\lambda = 0$.\footnote{Technically, here it is important that $V$ is a vector space over $\R$ or $\C$, since otherwise we cannot conclude from $\lambda^k = 0$ that $\lambda = 0$.}

\item Suppose $T$ is nilpotent and self adjoint.
By the spectral theorem, there exists an orthonormal basis with respect to which $T$ has a diagonal matrix, and the diagonal entries are the eigenvalues of $T$. By part (a), these entries are zero, and so the matrix is the zero matrix. \qedhere

\end{enumerate}
\end{proof}

\end{enumerate}

\end{document}
